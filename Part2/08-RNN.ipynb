{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-순환 신경망 (Recurrent Neural Network, RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "hidden_units = 128\n",
    "timesteps = 100\n",
    "input_dim = 3\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2, 10))) # \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10))) # batch_size, input_length(timesteps), input_dim\n",
    "model.summary() # batch_size, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_4 (SimpleRNN)    (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10), return_sequences=True)) \n",
    "# batch_size, input_length(timesteps), input_dim(단어 벡터의 차원)\n",
    "model.summary() # batch_size, input_length, output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-장단기 메모리 (Long Short-Term Memory, LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "장기 의존성 문제 (the problem of Long-Term Dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-게이트 순환 유닛 (Gated Recurrent Unit, GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_6 (GRU)                 (None, 10)                450       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 450\n",
      "Trainable params: 450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "hidden_size = 10\n",
    "timesteps = 10\n",
    "input_dim = 3\n",
    "\n",
    "# 3 x 10 + 10 + 10 * 10 = 140 -> SimpleRNN\n",
    "# GRU , 게이트 params 개수 추가해줘야 됨\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(hidden_size, input_shape=(timesteps, input_dim)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04-케라스의 SimpleRNN과 LSTM 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional\n",
    "\n",
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5,\n",
    "2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "print(np.shape(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5,\n",
    "2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.00543029 -0.9589752  -0.11370576]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3)\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[[ 0.4860671  -0.3600892   0.9999973 ]\n",
      "  [-0.89198697 -0.00982944  0.99997556]\n",
      "  [-0.28485563 -0.737735    0.997643  ]\n",
      "  [ 0.76006407  0.45950657  0.97987604]]], shape: (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True)\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[-0.13664734  0.90197337  0.99983746]\n",
      "  [-0.34359074  0.8098156   0.9949661 ]\n",
      "  [ 0.53233576 -0.29509205  0.29998806]\n",
      "  [-0.9248585  -0.9593232   0.9725801 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[-0.9248585 -0.9593232  0.9725801]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.10579669 -0.10569224 -0.2552316 ]], shape: (1, 3)\n",
      "last hidden state : [[ 0.10579669 -0.10569224 -0.2552316 ]], shape: (1, 3)\n",
      "last cell state : [[ 0.6434901  -0.17089057 -0.39580116]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
    "\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.\n",
    "shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.23962617 0.02055499 0.03025163]\n",
      "  [0.50783145 0.10866491 0.097845  ]\n",
      "  [0.57100165 0.14253806 0.16409256]\n",
      "  [0.4270816  0.13077904 0.18208344]]], shape: (1, 4, 3)\n",
      "last hidden state : [[0.4270816  0.13077904 0.18208344]], shape: (1, 3)\n",
      "last cell state : [[0.5049217  0.40734798 0.30246925]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_hidden_state, last_cell_state = lstm(train_X)\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_hidden_state,\n",
    "last_hidden_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.\n",
    "shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[0.63031393 0.63031393 0.63031393 0.7038734  0.7038734  0.7038734 ]], shape: (1, 6)\n",
      "forward state : [[0.63031393 0.63031393 0.63031393]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, \n",
    "                            return_sequences=False, \n",
    "                            return_state=True, \n",
    "                            kernel_initializer=k_init,\n",
    "                            bias_initializer=b_init,\n",
    "                            recurrent_initializer=r_init\n",
    "                            ))\n",
    "hidden_state, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.5511133  0.5511133  0.5511133  0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115756 0.59115756 0.59115756 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.63031393 0.63031393 0.63031393 0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
      "forward state : [[0.63031393 0.63031393 0.63031393]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, \n",
    "                            return_sequences=True, \n",
    "                            return_state=True, \n",
    "                            kernel_initializer=k_init,\n",
    "                            bias_initializer=b_init,\n",
    "                            recurrent_initializer=r_init\n",
    "                            ))\n",
    "\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-RNN 언어모델 (Recurrent Neural Network Language Model, RNNLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교사 강요.   \n",
    "원래 언어모델은 입력값 -> 출력값 -> 입력값, t 시점의 출력값이 t+1의 입력값으로 사용되나,  \n",
    "훈련시에는 정답 레이블을 이용해 t+1의 입력값을 입력해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06-RNN을 이용한 텍스트 생성 (Text Generation using RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n그의 말이 법이다\\n가는 말이 고와야 오는 말이 곱다 \\n\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단 어 집 합 의 크 기 : 12\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('단 어 집 합 의 크 기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5]\n",
      "[6, 1, 7]\n",
      "[8, 1, 9, 10, 1, 11]\n",
      "[]\n",
      "학 습 에 사 용 할 샘 플 의 개 수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text.split('\\n'):\n",
    "  encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "  print(encoded)\n",
    "  for i in range(1, len(encoded)):\n",
    "    sequence = encoded[:i+1]\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "print('학 습 에 사 용 할 샘 플 의 개 수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘 플 의 최 대 길 이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences) \n",
    "\n",
    "print('샘 플 의 최 대 길 이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n",
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 10)          120       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                1376      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 1s - loss: 2.4891 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4739 - accuracy: 0.0000e+00 - 4ms/epoch - 4ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4589 - accuracy: 0.0000e+00 - 4ms/epoch - 4ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4440 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4290 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4137 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.3981 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3819 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3651 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3475 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3290 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3096 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.2891 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.2676 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2450 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2214 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.1969 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.1714 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.1453 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1187 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.0920 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.0654 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.0394 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0145 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 1.9910 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 1.9694 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 1.9499 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9326 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9174 - accuracy: 0.3636 - 52ms/epoch - 52ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9038 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.8913 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.8794 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.8674 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8550 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.8419 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.8281 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.8137 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.7987 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.7834 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7679 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.7523 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.7366 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.7208 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.7050 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.6891 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.6732 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.6571 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6409 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.6247 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.6084 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.5920 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5757 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5593 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.5430 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.5266 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.5102 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.4937 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.4771 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.4605 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.4438 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.4270 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.4102 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.3934 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.3765 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.3596 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.3427 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.3257 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.3086 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.2914 - accuracy: 0.5455 - 3ms/epoch - 3ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.2741 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.2567 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.2392 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.2216 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.2039 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.1862 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.1684 - accuracy: 0.5455 - 4ms/epoch - 4ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.1506 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.1328 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.1150 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.0972 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 1.0793 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 1.0615 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 1.0438 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 1.0261 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 1.0085 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9910 - accuracy: 0.6364 - 4ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.9737 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.9564 - accuracy: 0.6364 - 16ms/epoch - 16ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.9393 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.9224 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.9056 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8890 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8726 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8563 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.8403 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.8244 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.8087 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.7933 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7781 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7631 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7483 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7337 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.7194 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.7054 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6916 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6781 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6648 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6518 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6390 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6265 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6143 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.6022 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5905 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5790 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5677 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5567 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5459 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5353 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5250 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5149 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.5051 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4954 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4860 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4768 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4678 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4590 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4504 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4420 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4338 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4258 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4180 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4103 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.4029 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3956 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3884 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3814 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3746 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3679 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3613 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3549 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3487 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3425 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3365 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3307 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.3249 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3192 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.3137 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.3083 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.3030 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2978 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2926 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2876 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2827 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2779 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2731 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2685 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2639 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2594 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2550 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2507 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2465 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2423 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2382 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2342 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2302 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.2263 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.2225 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2187 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.2150 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.2114 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.2078 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.2043 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.2009 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1975 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1942 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1909 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1877 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1845 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1814 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1783 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1753 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1724 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1694 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1666 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1638 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1610 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1583 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1556 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1530 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1504 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1479 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1454 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1430 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1406 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1382 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1359 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1336 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1314 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1292 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1271 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de20eb3010>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = tokenizer.word_index\n",
    "id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
    "\n",
    "def sentence_generation(model, tokenizer, current_word, n): \n",
    "  init_word = current_word\n",
    "  sentence = ''\n",
    "  \n",
    "  # n번 반 복\n",
    "  for _ in range(n):\n",
    "    # 현 재 단 어 에 대 한 정 수 인 코 딩 과 패 딩\n",
    "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "    # 입 력 한 X(현 재 단 어)에 대 해 서 Y를 예 측 하 고 Y(예 측 한 단 어)를 result에 저 장\n",
    "    result = model.predict(encoded, verbose=0)\n",
    "    result = np.argmax(result, axis=1)\n",
    "\n",
    "    word = id_to_word[result[0]]    \n",
    "    \n",
    "    current_word = current_word + ' ' + word\n",
    "      \n",
    "    # 예 측 단 어 를 문 장 에 저 장\n",
    "    sentence = sentence + ' ' + word\n",
    "      \n",
    "  sentence = init_word + sentence\n",
    "  \n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그 의 말이 있는\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '그 의', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가 는 말이 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '가 는', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/archive/ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324 entries, 0 to 1323\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   articleID         1324 non-null   object\n",
      " 1   articleWordCount  1324 non-null   int64 \n",
      " 2   byline            1324 non-null   object\n",
      " 3   documentType      1324 non-null   object\n",
      " 4   headline          1324 non-null   object\n",
      " 5   keywords          1324 non-null   object\n",
      " 6   multimedia        1324 non-null   int64 \n",
      " 7   newDesk           1324 non-null   object\n",
      " 8   printPage         1324 non-null   int64 \n",
      " 9   pubDate           1324 non-null   object\n",
      " 10  sectionName       1324 non-null   object\n",
      " 11  snippet           1324 non-null   object\n",
      " 12  source            1324 non-null   object\n",
      " 13  typeOfMaterial    1324 non-null   object\n",
      " 14  webURL            1324 non-null   object\n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 155.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = []\n",
    "\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = [word for word in headline if word != 'Unknown']\n",
    "print(len(headline))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    # 구두점 제거와 동시에 소문자화\n",
    "    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for sentence in preprocessed_headline:\n",
    "\n",
    "    # 각 샘플에 대한 정수 인코딩\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print(len(sequences))\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = tokenizer.word_index\n",
    "id_to_word = dict((v, k) for k, v in word_to_id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 582번 단어 : {}'.format(id_to_word[582]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 24\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,  99],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  99, 269],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  99, 269, 371]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 10)          34940     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               71168     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3494)              450726    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,834\n",
      "Trainable params: 556,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAFgCAIAAADvnfF3AAAABmJLR0QA/wD/AP+gvaeTAAAZk0lEQVR4nO3dTWzb5hkH8If+6jAsdYYk9jrkAxg8dUWBeMMudg8xlgQoWow6FEpiJ06KoktHYz0sTY4ycnCBHia1O2RwIG+HwVglOzlJGLbDZGA5RNqhgIxgCKRuRek428QGmNgAA2rPeXd4Y46hJIqWH4m09P+dxA+9fPjxF8lXX4oQggBgd3r8LgCgEyBIAAwQJAAGCBIAgz77QC6X+/DDD/0qBWAPee+998bHx63BZ85IDx48uH37dttLAj/l8/l8Pu93FXvM7du3Hzx4YB/TVz3TrVu32lUP+O/MmTOEnb5DiqI4xuAeCYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAz8CZJhGKlUKhwOt6gR+6TZ2dnZ2dndLKgVglkVNK3G95Ha4Pr16zdv3mxdIyzte2Sa5v379+/du5fJZNLpdHsW2pBpmvv37+f6rbXqr9+04lfc7DW3Z4mchM3S0pJjTOtUL523EZb2vYhGo9FotG2L80hG2suckUgkEok0nK1Sqch1rFQqu66uNkfN5XK51UtsGhEtLS3Zx/hzRuokc3NzRPT+++/7Xcj/maa5sLDA2+bg4KDjAa/qmoeGhlq6RF5N3iMZhhGPxxVFCYfDKysr9OxtSSaTURRlZmZmbW2NiFKplH2wZjuOqdXtS6ZpytbC4XCpVLI3VXOS4z6qushwOGxf7srKSjgcVhQlHo8bhtHcxmnIe1WGYWQyGTlpYWFBbii5dso22Yh9MBaLZTIZa2SrV8GvmmX25Pyzs7PWMSPF43E5mzXSKq/60JUFm6Y5MzPT5L2r/fTk8dKuXC6rqppMJoUQ2WyWiAqFgqqqssFCoSCEyOVyRKRpWi6XE0Loui4H7SdHIpJTZYNEVC6X67Uvn6WqqqZp8lyfTCbtq1BzklWVNY99uY6q5KWFnGS14GWDiB1eSXqvyqpBTqpUKpqmEVGxWLSufGQj8lnWoPd6PF7aOdpsT83uayGbLZfL9qVbB559TlVVXQ4t+7oUCgXHc+ttCselXTNBkgeZvdFoNFq92jsaLBaLRJRIJFzalwd6sViU462rdvdJ3suonhSLxRpujZrP3en83qsqFApWYd6f5aK5ILWnZve1iEaj1kFvnzMWixGRruvW0mVyRKND1/vNGE+QrATbid0FyT6mXvvyFajmU1wmeS/D0Yj3Y3GnM++oKpcNtaNn1dOGIDVds5e10HVdJseaU+ZWvigLIWKxmBUqj4duQ8QSpHpL9b6hazbScK129BQve84xKHeAfPWyv4h60cSeaPNBWc+eDlIikVBVVV7O2OeUr4mVSkVeWDZssInd5whS82/IOu71Wcj1b1377kZHR9Pp9MOHD+XNazKZvHr1aptr8Mi+ofYKxppnZmaIKJVKvfPOOzdu3AiFQjWX9Yc//OHOnTtvvvmmY2orDq1mgpRIJIhocXHRNE3a7gbZZR2rq6tENDEx4dK+HC/nrFlSzUneZTKZEydOXL16VQiRTqcnJyd301qLyIPg9ddf97uQHeCtOZ/Py+NkamqKiI4ePVo9z+joqKZpU1NTCwsLY2Nj1vhWHLpP2U9P3nvtHI3ouu54+8watHpL7INi+2o1m82K7b4U6zqqZvtiu5NHVVU5KHtdiEjTtHqT3njjjZplyCKtPgk5tXrjaJpmFexip29W1ts4LlXJC85KpRKNRlVVle1YvWFiu7eKtjusrF7Qhlenzb0h24aaHV18knyK7MWV8+u6bl3a2XeWnNO6U3JsefuhVXNB7ojlHkkIoeu6fDtfHsTi2aOw4aCUzWblttA0TSbKpX1rvNwT8hCXXZly89WctKOq7D2hloadoVSl4dbbUVXygVVbIpGw4qrruhyZTqeFEPatIe/xotFowxcCL0GqXsdW1+y+RNmafX7Zg2c/VGTjVkeuxeXQtdLeEHEFqSMVi0XHnpAvdX7VI3kMZ9O8dzZ41+qavXB0M/CqDhK+RvFUKpUKhUKOC+7h4WHHaQ32iuXlZfn/AO2BID318ccfLyws2D8uVCqVlpeX/e1ysD6m1LrPK7Hzt+bZ2VnrA0EnT55s23IRpKcWFxf37dv3wQcfWJ/dWl9fv3z5Mtk+ElZTvQabe5bD8PCw40Hw+VuzvKZIJBLyw8Rtg09/PzU4ODg5OTk5OTk/P++YJBrdbdfU3LNa0Uib+Vvz5cuX5ctfm+GMBMAAQQJggCABMECQABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADGp8+rudX4cC3+XzecJO37VngnTkyJFIJOJXKVDT/fv3ieill15qUfv2H9kBjyKRyJEjR+xjlL34jZeucvbsWSJaXl72uxBwg3skAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAGCBIAAwQJgAGCBMAAQQJggCABMECQABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAG+Me+wPnd7373m9/85smTJ3KwWCwS0YsvvigHe3p63n777QsXLvhWH9SCIAXO6urq97//fZcZCoXC6Oho2+oBLxCkIPre974nT0TVRkZGPv300zbXAw3hHimILl682N/fXz2+v7//rbfean890BDOSEH02WefjYyM1Nw1n3766cjISPtLAnc4IwXRd77znR/84AeKothHKorywx/+ECkKJgQpoC5dutTb22sf09vbe+nSJb/qAXe4tAsowzBeeOEFqxOciHp6eh4+fPitb33Lx6qgHpyRAmpoaOjEiRPWSam3t3diYgIpCiwEKbguXrzoMgiBgku74Pryyy8PHjy4ublJRP39/YZh7N+/3++ioDackYLr+eeff+211/r6+vr6+l5//XWkKMgQpECbnp7e2tra2trCh+sCro+xrVwu9+DBA8YGYXNzc2BgQAjx1VdfLS8v+11ORzly5Mj4+Dhbc4JPJBJhKwugxSKRCOPBz3lGksXdunWLt80u98c//lFRlFdffdU+cnl5+dy5cwIdRc06c+YMb4PMQQJ2p0+f9rsEaAxBCrq+PuyjPQC9dgAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAwZ4MkmEYqVQqHA63qBH7pNnZ2dnZ2d0sqDNgm7vbk58svn79+s2bN1vXCEv7Hpmmef/+/Xv37mUymXQ6zdiy44daHXb6XaZO2uatwPkrQvLLUu35Yp88SnZZvEsjLO17IV9633///R0tzuMX+0zTlD+ZYp+zVCq9+OKLTaxax2xzasGxuifPSJ1kbm6OtoPEbnBwsHpkKBRqxbK6nD/3SIZhxONxRVHC4fDKygo9e4mcyWQURZmZmVlbWyOiVCplH6zZjmNqdfuSaZqytXA4XCqV7E3VnOS4pq8uMhwO25e7srISDocVRYnH44Zh8G0wNvZXfWxzToy//xCJRLz8oES5XFZVNZlMCiGy2SwRFQoFVVVlPYVCQQiRy+WISNO0XC4nhNB1XQ5ajciZ5VTZIBGVy+V67ctnqaqqaVqlUhFCJJNJ+xaoOcmqyprHvlxHVfIOR06yWvC4hXe6L5aWlppoWRZsTermbe7xWPXOhyDJFf5/BUTRaFRUHUw7GpT/b5dIJFzalxu9WCzK8ZVKxWrEZZL3MqonxWKxhluj5nMb2mmQ7FyW2z3bvBOCZL3GOPbubnaqfUy99jVNq/cUl0ney3A0Ul2hix3NLJjOSNXL7Z5t3glBqre2XDvVY/vuT2lipxYKBSKSlzfycXDOSPZB96ldss3Zg+Rbr12pVGLvPpKvT61r393o6Gg6nS6VSoqiyBuGycnJdhbghXUgcsE2l3zotUskEkS0uLhomiZt9/bsss3V1VUimpiYcGlfjpdz1iyp5iTvMpnMiRMnrl69KoRIp9MBTJFlbW1t9x8dwDZ/BuPZzXuvnaMGXdetkbIPxxq0OoXsg2L7ojybzYrtLiPrnF6zfbF9h6CqqhyUnUtEpGlavUlvvPFGzTJkkdb9sZxavW01TbMKdmG1I5v1wuOlnf0O3qLruuya6+Zt3gn3SEIIXdej0ai1QcWzW6ThoJTNZuWu1TRN7l2X9q3x8lJEbm55MSC3e81JO6rK3olv36/um6L6UPCyAb0EqbplO+uI7MJtLloQpL36EaEAKpVKX/va144ePWof09yHcRrCb39LTW9z9mN1T376O4BSqVQoFLLvUSIaHh52vMQCo0Btc3zWjsfHH3/8+PHjV1991dqvpVLpz3/+8+XLl/0trIMFapvjjMRjcXFx3759H3zwgaIoiqLMzs6ur6/LPaq48rvwPcxlm7cf7pH2JNwj7RLukQCCCEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAyYv4+0vr6+vLzM2yZUk7+Kik3dtPX19cOHD3O2yPi19UgkwlkZQCsF9zcboBXOnj1LOPkEHu6RABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAGCBIAAwQJgAGCBMAAQQJggCABMECQABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYMP+HLOzeX/7yl9XVVWvws88+I6JEImGNOX78+NjYmA+VQX0IUuAYhvHTn/60t7e3p6eHiOR/k7777rtE9OTJk62trXQ67XOJUAX/IRs4m5ubBw8e/PLLL2tO3bdv36NHjwYGBtpcFbjDPVLg9Pf3T05O1oxKf3//1NQUUhRACFIQTU1NbWxsVI/f3Nw8f/58++uBhnBpF0RPnjz59re/XS6XHeMPHTr0r3/9S947QaBglwRRT0/P9PS04xJuYGDgzTffRIqCCXsloKqv7jY2NqampvyqB9zh0i64RkZG/v73v1uDx44d+/zzz/0rB9zgjBRc09PT/f398vHAwMBbb73lbz3gAmek4Prb3/723e9+1xosFouhUMjHesAFzkjBNTIycvz4cUVRFEU5fvw4UhRkCFKgXbp0qbe3t7e399KlS37XAm5waRdo//jHP44cOSKEWFtbO3z4sN/lQH2iCywtLfm9mbvX0tKS3/u/Hbro098Bj9NHH31ERFeuXHGM/9Of/qQoyqlTp/woarfOnTvndwlt0kVBOnv2rN8luLl16xbVKlJG6MCBAz7UtGsIEgTFHo1Qt0GvHQADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAGCBIAAwQJgAGCBMAAQQJggCABMECQnjIMI5VKhcNhvwuBPQlBeur69etTU1OZTMZ9NtM0FUVpT0nVlCo1Z8vn8zMzM4qizMzMrKysWDVXP91FPp+v2XLDpXcnBOmp+fl5L7PduXOn1ZW4EEJYPwheqVRErd/byOfz4+PjExMTQoj5+fkDBw5cvHjRmppMJq1vR1ttSslkkoh0XZfjf/vb31Y3bo0sl8s1l961EKQdME1zYWHB3xqGhobkg8HBwZozyGN9cnJSDo6Ojs7NzVlTrfHVXnvtNSI6evQoEcVisZs3b66trdlnWFtbGxkZcZQBEoLkJh6PK4qysLBgGIaiKLFYTF77yQsb+21VJpORl1Ly4EulUvbBdnr48CER2f88c3R0VD6wzjY1DQ4OWjOcPn2aiO7evWuf4e7du3I81NDe31rxh/zZk4azOTZILBbTdV0IUalUotEobf8LpTWPqqpysFAoCCFyuRwRaZqWy+WEEPKg1DTNY5GRSCQSiXiZ033HFQoFOUMikZCXfzttR47UNM0xVa7Ljg4b6ppfEUKQ/s9xiND2nYDYvjOpOY/3QXdcQRJCFItFGQMiSiaT9eLkHqRsNktE8kVBCFEoFLLZrJelO5rqkiDh0q4uTdOGh4dTqZRpmkNDQ2Lv3FuHQqH5+flcLqdp2tTU1P79+xv2RlY7efIk2XoXbt++LcdATQhSXVeuXFFVVR6I8Xjc73J2bGxsTMZJVdVwONxElpLJpOxyMAzj5ZdfbkWRHQNBqisUCqXT6UKhoGnatWvXgp+lmZkZIlIUxTRNa+TY2NiNGzeIqIn3ml955RUiunv37srKinwM9SBIdckjcnR0dH5+vlAoXLt2ze+K3OTz+YmJCfn4k08+sU+SPdpW14h3R48ejUajU1NTDx8+lI1APQjSU4ZhOB4QUSwWk/3X3/zmN2OxGG0fjoZhxONxa055BnC0ULNBxjrt5JuwL730khw8deqU/ECDrC2VShGR/d0kl/IcxUciEdruDXd5FqDX7qnqbUJE5XJZ5icWi8mRsnM5Go06/nK8uoWdbmQvvXbuu9L6rIMQolgsJhIJOT4ajRaLRfd2ao6XI60e/CYOHuqaXruu+FuX5eXlc+fOBXxNz5w5Q9u/AN4xFEVZWloK+K+us8ClHQADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAGCBIAAwQJgAGCBMAAQQJggCABMECQABggSAAMECQABggSAIM+vwtonz3x7wl7okio1hVfNV9fX3f8jPUe8tFHHxHRlStX/C6kSa+88srhw4f9rqLluiJIe5r8wYPl5WW/CwE3uEcCYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAGCBIAAwQJgAGCBMAAQQJggCABMECQABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwKCL/vpyr/jPf/7z1VdfWYMbGxtE9O9//9sa89xzz33961/3oTKoD//YFzi/+tWv3n33XZcZbty48bOf/axt9YAXCFLgfPHFFy+88MLW1lbNqb29vf/85z8PHTrU5qrAHe6RAufQoUMnT57s7e2tntTb23vq1CmkKIAQpCCanp6ueaUghJienm5/PdAQLu2C6PHjx4cOHbJ3OUgDAwNffPHF888/70tV4AJnpCDat2/fj3/84/7+fvvIvr6+cDiMFAUTghRQFy5c+O9//2sfs7W1deHCBb/qAXe4tAuojY2NgwcPPn782BrzjW9849GjR88995yPVUE9OCMF1MDAQCQSGRgYkIP9/f1nz55FigILQQqu8+fPy481ENHm5ub58+f9rQdc4NIuuJ48eTI8PPzo0SMiOnDgQLlcrvnmEgQBzkjB1dPTc+HChYGBgf7+/unpaaQoyBCkQJuamtrY2MB1XfB1wqe/P/zww1wu53cVrSI/6P2LX/zC70JaZXx8/L333vO7it3qhDNSLpfL5/N+V9Eqx44dO3bsmGPk+vr67du3famHVz6f74wXwU44IxHR2NjYrVu3/K6iJf76178S0csvv2wfuby8fO7cuQ5Y5TNnzvhdAo8OCVIHc0QIgqkTLu0AfIcgATBAkAAYIEgADBAkAAYIEgADBAmAAYIEwABBAmCAIAEwQJAAGCBIAAwQJAAG3RskwzBSqVQ4HPa7EOgE3fs1iuvXr9+8edPvKsg0zfv379+7dy+TyaTTacaWFUWpHhmLxUKh0IkTJwYHBxmXBd17Rpqfn/e7BCKiWCz2+9///p133slkMrwtCyHK5bJ8XKlUhBBCiNOnTy8sLFy8eNEwDN7FdbnuDVJAzM3Nzc3NtajxoaEh+cA6/4yOjv76178mop/85CemabZouV2ou4JkmmYqlVIUJRwOl0ol+yTDMOLxuJy0srJCz95EZTIZOWltbc16ipx/YWHBMAzrOqq6naAZGhr6+c9/nslk7ty5Y43sntVvFbH3RSKRSCTiZU5VVTVNk9c5yWTS2gLlcllV1WQyKYTIZrNEVCgUVFWVM+RyOSGErutEpGmabCoWi+m6LoSoVCrRaNSlHS+F7XRfLC0teZy/ZsuVSsW+Lj6uvvd9F3BdFCR5K18sFuWgPJjkESBDZc1JRNFoVFQdhfZBIiqXy/KxvBVxaaehNgfJMd7H1UeQAsTjztA0zXFIWUeG9errOFe7HEmytWQyad3Hu7TTkL9B8nH1EaQA8bgzqvdrvSOm3lPsg8Vi0TpuYrFYvUV41OYgybOxdbrwcfU7Jkjd1dngztH94C4UCqXT6UKhoGnatWvX4vF4c+344pNPPiGiH/3oR/aR3bP6rdBFQUokEkS0urpab9Li4qLsEZZdT+6tKYpimubo6Oj8/HyhULh27Vpz7bSfYRi//OUvVVU9efKkHNNVq98qfp8SGXi8PJD9Tqqqyu4m2a1ERJqmWW9cWnRdd7ybaXVOyJtsIopGo7IpXdfl5U3NdhoWZrVsv99w5/HSrrpl2R2nqqrVVVCv7Pasfsdc2nVRkIQQuq7Lu2QZHtlXK48MXddlN66maXL3O15uqgfL5XIsFiPbTULNdtw199LmJUjVLctSZXd29ZbxZfU7Jkid8Edj8vejO+CHsL2Tv/2NfRccXXSPBNA6CBIAg+79GkXb1Pw6g6UDLs+AEKQ2QFS6AS7tABggSAAMECQABggSAAMECYABggTAAEECYIAgATBAkAAYIEgADBAkAAYIEgADBAmAQYd8+jufz8vvWnaJ9fV12v566Z6Wz+fHxsb8roJBJwRpfHzc7xLa7fDhw5FIxO8qGIyNjXXG7uuE32wA8B3ukQAYIEgADBAkAAYIEgCD/wFVAtTSIg6IEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "244/244 - 6s - loss: 7.6560 - accuracy: 0.0277 - 6s/epoch - 26ms/step\n",
      "Epoch 2/200\n",
      "244/244 - 4s - loss: 7.1219 - accuracy: 0.0302 - 4s/epoch - 17ms/step\n",
      "Epoch 3/200\n",
      "244/244 - 4s - loss: 6.9786 - accuracy: 0.0379 - 4s/epoch - 17ms/step\n",
      "Epoch 4/200\n",
      "244/244 - 4s - loss: 6.8543 - accuracy: 0.0433 - 4s/epoch - 17ms/step\n",
      "Epoch 5/200\n",
      "244/244 - 4s - loss: 6.7033 - accuracy: 0.0446 - 4s/epoch - 16ms/step\n",
      "Epoch 6/200\n",
      "244/244 - 6s - loss: 6.5307 - accuracy: 0.0468 - 6s/epoch - 23ms/step\n",
      "Epoch 7/200\n",
      "244/244 - 5s - loss: 6.3434 - accuracy: 0.0525 - 5s/epoch - 21ms/step\n",
      "Epoch 8/200\n",
      "244/244 - 5s - loss: 6.1434 - accuracy: 0.0592 - 5s/epoch - 19ms/step\n",
      "Epoch 9/200\n",
      "244/244 - 4s - loss: 5.9497 - accuracy: 0.0616 - 4s/epoch - 18ms/step\n",
      "Epoch 10/200\n",
      "244/244 - 4s - loss: 5.7685 - accuracy: 0.0636 - 4s/epoch - 17ms/step\n",
      "Epoch 11/200\n",
      "244/244 - 4s - loss: 5.5943 - accuracy: 0.0736 - 4s/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "244/244 - 4s - loss: 5.4327 - accuracy: 0.0751 - 4s/epoch - 18ms/step\n",
      "Epoch 13/200\n",
      "244/244 - 4s - loss: 5.2760 - accuracy: 0.0819 - 4s/epoch - 16ms/step\n",
      "Epoch 14/200\n",
      "244/244 - 4s - loss: 5.1292 - accuracy: 0.0918 - 4s/epoch - 16ms/step\n",
      "Epoch 15/200\n",
      "244/244 - 4s - loss: 4.9861 - accuracy: 0.1003 - 4s/epoch - 16ms/step\n",
      "Epoch 16/200\n",
      "244/244 - 4s - loss: 4.8453 - accuracy: 0.1102 - 4s/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "244/244 - 4s - loss: 4.7141 - accuracy: 0.1185 - 4s/epoch - 16ms/step\n",
      "Epoch 18/200\n",
      "244/244 - 4s - loss: 4.5813 - accuracy: 0.1367 - 4s/epoch - 17ms/step\n",
      "Epoch 19/200\n",
      "244/244 - 4s - loss: 4.4578 - accuracy: 0.1531 - 4s/epoch - 16ms/step\n",
      "Epoch 20/200\n",
      "244/244 - 4s - loss: 4.3336 - accuracy: 0.1676 - 4s/epoch - 16ms/step\n",
      "Epoch 21/200\n",
      "244/244 - 4s - loss: 4.2131 - accuracy: 0.1830 - 4s/epoch - 16ms/step\n",
      "Epoch 22/200\n",
      "244/244 - 4s - loss: 4.1000 - accuracy: 0.2071 - 4s/epoch - 15ms/step\n",
      "Epoch 23/200\n",
      "244/244 - 4s - loss: 3.9852 - accuracy: 0.2175 - 4s/epoch - 15ms/step\n",
      "Epoch 24/200\n",
      "244/244 - 4s - loss: 3.8785 - accuracy: 0.2400 - 4s/epoch - 15ms/step\n",
      "Epoch 25/200\n",
      "244/244 - 4s - loss: 3.7684 - accuracy: 0.2555 - 4s/epoch - 15ms/step\n",
      "Epoch 26/200\n",
      "244/244 - 4s - loss: 3.6660 - accuracy: 0.2735 - 4s/epoch - 15ms/step\n",
      "Epoch 27/200\n",
      "244/244 - 4s - loss: 3.5653 - accuracy: 0.2828 - 4s/epoch - 16ms/step\n",
      "Epoch 28/200\n",
      "244/244 - 4s - loss: 3.4654 - accuracy: 0.3045 - 4s/epoch - 16ms/step\n",
      "Epoch 29/200\n",
      "244/244 - 4s - loss: 3.3725 - accuracy: 0.3171 - 4s/epoch - 15ms/step\n",
      "Epoch 30/200\n",
      "244/244 - 4s - loss: 3.2812 - accuracy: 0.3342 - 4s/epoch - 15ms/step\n",
      "Epoch 31/200\n",
      "244/244 - 4s - loss: 3.1910 - accuracy: 0.3519 - 4s/epoch - 15ms/step\n",
      "Epoch 32/200\n",
      "244/244 - 4s - loss: 3.1076 - accuracy: 0.3634 - 4s/epoch - 15ms/step\n",
      "Epoch 33/200\n",
      "244/244 - 4s - loss: 3.0254 - accuracy: 0.3802 - 4s/epoch - 16ms/step\n",
      "Epoch 34/200\n",
      "244/244 - 4s - loss: 2.9470 - accuracy: 0.3963 - 4s/epoch - 15ms/step\n",
      "Epoch 35/200\n",
      "244/244 - 4s - loss: 2.8694 - accuracy: 0.4091 - 4s/epoch - 15ms/step\n",
      "Epoch 36/200\n",
      "244/244 - 4s - loss: 2.7966 - accuracy: 0.4228 - 4s/epoch - 16ms/step\n",
      "Epoch 37/200\n",
      "244/244 - 4s - loss: 2.7220 - accuracy: 0.4400 - 4s/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "244/244 - 4s - loss: 2.6546 - accuracy: 0.4517 - 4s/epoch - 16ms/step\n",
      "Epoch 39/200\n",
      "244/244 - 4s - loss: 2.5866 - accuracy: 0.4630 - 4s/epoch - 16ms/step\n",
      "Epoch 40/200\n",
      "244/244 - 4s - loss: 2.5232 - accuracy: 0.4780 - 4s/epoch - 15ms/step\n",
      "Epoch 41/200\n",
      "244/244 - 4s - loss: 2.4617 - accuracy: 0.4887 - 4s/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "244/244 - 4s - loss: 2.3964 - accuracy: 0.5067 - 4s/epoch - 16ms/step\n",
      "Epoch 43/200\n",
      "244/244 - 4s - loss: 2.3353 - accuracy: 0.5175 - 4s/epoch - 16ms/step\n",
      "Epoch 44/200\n",
      "244/244 - 4s - loss: 2.2810 - accuracy: 0.5247 - 4s/epoch - 15ms/step\n",
      "Epoch 45/200\n",
      "244/244 - 4s - loss: 2.2263 - accuracy: 0.5370 - 4s/epoch - 15ms/step\n",
      "Epoch 46/200\n",
      "244/244 - 4s - loss: 2.1686 - accuracy: 0.5563 - 4s/epoch - 16ms/step\n",
      "Epoch 47/200\n",
      "244/244 - 4s - loss: 2.1203 - accuracy: 0.5572 - 4s/epoch - 16ms/step\n",
      "Epoch 48/200\n",
      "244/244 - 4s - loss: 2.0672 - accuracy: 0.5723 - 4s/epoch - 15ms/step\n",
      "Epoch 49/200\n",
      "244/244 - 4s - loss: 2.0154 - accuracy: 0.5873 - 4s/epoch - 15ms/step\n",
      "Epoch 50/200\n",
      "244/244 - 4s - loss: 1.9682 - accuracy: 0.5950 - 4s/epoch - 15ms/step\n",
      "Epoch 51/200\n",
      "244/244 - 4s - loss: 1.9232 - accuracy: 0.6043 - 4s/epoch - 15ms/step\n",
      "Epoch 52/200\n",
      "244/244 - 4s - loss: 1.8741 - accuracy: 0.6146 - 4s/epoch - 15ms/step\n",
      "Epoch 53/200\n",
      "244/244 - 4s - loss: 1.8294 - accuracy: 0.6254 - 4s/epoch - 15ms/step\n",
      "Epoch 54/200\n",
      "244/244 - 4s - loss: 1.7869 - accuracy: 0.6360 - 4s/epoch - 16ms/step\n",
      "Epoch 55/200\n",
      "244/244 - 4s - loss: 1.7454 - accuracy: 0.6431 - 4s/epoch - 15ms/step\n",
      "Epoch 56/200\n",
      "244/244 - 4s - loss: 1.7017 - accuracy: 0.6531 - 4s/epoch - 16ms/step\n",
      "Epoch 57/200\n",
      "244/244 - 4s - loss: 1.6610 - accuracy: 0.6621 - 4s/epoch - 16ms/step\n",
      "Epoch 58/200\n",
      "244/244 - 4s - loss: 1.6233 - accuracy: 0.6703 - 4s/epoch - 16ms/step\n",
      "Epoch 59/200\n",
      "244/244 - 4s - loss: 1.5857 - accuracy: 0.6809 - 4s/epoch - 15ms/step\n",
      "Epoch 60/200\n",
      "244/244 - 4s - loss: 1.5472 - accuracy: 0.6892 - 4s/epoch - 15ms/step\n",
      "Epoch 61/200\n",
      "244/244 - 4s - loss: 1.5086 - accuracy: 0.6952 - 4s/epoch - 15ms/step\n",
      "Epoch 62/200\n",
      "244/244 - 4s - loss: 1.4756 - accuracy: 0.7017 - 4s/epoch - 16ms/step\n",
      "Epoch 63/200\n",
      "244/244 - 4s - loss: 1.4392 - accuracy: 0.7099 - 4s/epoch - 16ms/step\n",
      "Epoch 64/200\n",
      "244/244 - 4s - loss: 1.4051 - accuracy: 0.7187 - 4s/epoch - 15ms/step\n",
      "Epoch 65/200\n",
      "244/244 - 4s - loss: 1.3724 - accuracy: 0.7236 - 4s/epoch - 16ms/step\n",
      "Epoch 66/200\n",
      "244/244 - 4s - loss: 1.3384 - accuracy: 0.7293 - 4s/epoch - 15ms/step\n",
      "Epoch 67/200\n",
      "244/244 - 4s - loss: 1.3074 - accuracy: 0.7372 - 4s/epoch - 16ms/step\n",
      "Epoch 68/200\n",
      "244/244 - 4s - loss: 1.2722 - accuracy: 0.7450 - 4s/epoch - 16ms/step\n",
      "Epoch 69/200\n",
      "244/244 - 4s - loss: 1.2453 - accuracy: 0.7489 - 4s/epoch - 15ms/step\n",
      "Epoch 70/200\n",
      "244/244 - 4s - loss: 1.2179 - accuracy: 0.7583 - 4s/epoch - 15ms/step\n",
      "Epoch 71/200\n",
      "244/244 - 4s - loss: 1.1896 - accuracy: 0.7606 - 4s/epoch - 16ms/step\n",
      "Epoch 72/200\n",
      "244/244 - 4s - loss: 1.1589 - accuracy: 0.7646 - 4s/epoch - 16ms/step\n",
      "Epoch 73/200\n",
      "244/244 - 4s - loss: 1.1288 - accuracy: 0.7741 - 4s/epoch - 15ms/step\n",
      "Epoch 74/200\n",
      "244/244 - 4s - loss: 1.1034 - accuracy: 0.7783 - 4s/epoch - 17ms/step\n",
      "Epoch 75/200\n",
      "244/244 - 4s - loss: 1.0769 - accuracy: 0.7843 - 4s/epoch - 17ms/step\n",
      "Epoch 76/200\n",
      "244/244 - 4s - loss: 1.0509 - accuracy: 0.7908 - 4s/epoch - 15ms/step\n",
      "Epoch 77/200\n",
      "244/244 - 4s - loss: 1.0273 - accuracy: 0.7953 - 4s/epoch - 15ms/step\n",
      "Epoch 78/200\n",
      "244/244 - 4s - loss: 1.0026 - accuracy: 0.7983 - 4s/epoch - 15ms/step\n",
      "Epoch 79/200\n",
      "244/244 - 4s - loss: 0.9784 - accuracy: 0.8055 - 4s/epoch - 16ms/step\n",
      "Epoch 80/200\n",
      "244/244 - 4s - loss: 0.9532 - accuracy: 0.8156 - 4s/epoch - 16ms/step\n",
      "Epoch 81/200\n",
      "244/244 - 4s - loss: 0.9317 - accuracy: 0.8149 - 4s/epoch - 16ms/step\n",
      "Epoch 82/200\n",
      "244/244 - 4s - loss: 0.9102 - accuracy: 0.8219 - 4s/epoch - 15ms/step\n",
      "Epoch 83/200\n",
      "244/244 - 4s - loss: 0.8897 - accuracy: 0.8246 - 4s/epoch - 18ms/step\n",
      "Epoch 84/200\n",
      "244/244 - 4s - loss: 0.8691 - accuracy: 0.8263 - 4s/epoch - 16ms/step\n",
      "Epoch 85/200\n",
      "244/244 - 4s - loss: 0.8465 - accuracy: 0.8347 - 4s/epoch - 16ms/step\n",
      "Epoch 86/200\n",
      "244/244 - 4s - loss: 0.8271 - accuracy: 0.8361 - 4s/epoch - 16ms/step\n",
      "Epoch 87/200\n",
      "244/244 - 4s - loss: 0.8077 - accuracy: 0.8410 - 4s/epoch - 16ms/step\n",
      "Epoch 88/200\n",
      "244/244 - 4s - loss: 0.7888 - accuracy: 0.8467 - 4s/epoch - 16ms/step\n",
      "Epoch 89/200\n",
      "244/244 - 4s - loss: 0.7700 - accuracy: 0.8492 - 4s/epoch - 16ms/step\n",
      "Epoch 90/200\n",
      "244/244 - 4s - loss: 0.7525 - accuracy: 0.8536 - 4s/epoch - 16ms/step\n",
      "Epoch 91/200\n",
      "244/244 - 4s - loss: 0.7357 - accuracy: 0.8562 - 4s/epoch - 16ms/step\n",
      "Epoch 92/200\n",
      "244/244 - 4s - loss: 0.7185 - accuracy: 0.8579 - 4s/epoch - 16ms/step\n",
      "Epoch 93/200\n",
      "244/244 - 4s - loss: 0.7021 - accuracy: 0.8640 - 4s/epoch - 16ms/step\n",
      "Epoch 94/200\n",
      "244/244 - 4s - loss: 0.6856 - accuracy: 0.8648 - 4s/epoch - 16ms/step\n",
      "Epoch 95/200\n",
      "244/244 - 4s - loss: 0.6702 - accuracy: 0.8676 - 4s/epoch - 16ms/step\n",
      "Epoch 96/200\n",
      "244/244 - 4s - loss: 0.6549 - accuracy: 0.8674 - 4s/epoch - 16ms/step\n",
      "Epoch 97/200\n",
      "244/244 - 4s - loss: 0.6425 - accuracy: 0.8736 - 4s/epoch - 16ms/step\n",
      "Epoch 98/200\n",
      "244/244 - 4s - loss: 0.6271 - accuracy: 0.8750 - 4s/epoch - 16ms/step\n",
      "Epoch 99/200\n",
      "244/244 - 4s - loss: 0.6113 - accuracy: 0.8766 - 4s/epoch - 16ms/step\n",
      "Epoch 100/200\n",
      "244/244 - 4s - loss: 0.5990 - accuracy: 0.8803 - 4s/epoch - 17ms/step\n",
      "Epoch 101/200\n",
      "244/244 - 4s - loss: 0.5870 - accuracy: 0.8824 - 4s/epoch - 16ms/step\n",
      "Epoch 102/200\n",
      "244/244 - 4s - loss: 0.5744 - accuracy: 0.8827 - 4s/epoch - 16ms/step\n",
      "Epoch 103/200\n",
      "244/244 - 4s - loss: 0.5588 - accuracy: 0.8868 - 4s/epoch - 17ms/step\n",
      "Epoch 104/200\n",
      "244/244 - 4s - loss: 0.5485 - accuracy: 0.8868 - 4s/epoch - 16ms/step\n",
      "Epoch 105/200\n",
      "244/244 - 4s - loss: 0.5376 - accuracy: 0.8930 - 4s/epoch - 16ms/step\n",
      "Epoch 106/200\n",
      "244/244 - 4s - loss: 0.5268 - accuracy: 0.8932 - 4s/epoch - 16ms/step\n",
      "Epoch 107/200\n",
      "244/244 - 4s - loss: 0.5167 - accuracy: 0.8952 - 4s/epoch - 16ms/step\n",
      "Epoch 108/200\n",
      "244/244 - 4s - loss: 0.5048 - accuracy: 0.8957 - 4s/epoch - 16ms/step\n",
      "Epoch 109/200\n",
      "244/244 - 4s - loss: 0.4942 - accuracy: 0.8986 - 4s/epoch - 15ms/step\n",
      "Epoch 110/200\n",
      "244/244 - 6s - loss: 0.4859 - accuracy: 0.8991 - 6s/epoch - 26ms/step\n",
      "Epoch 111/200\n",
      "244/244 - 4s - loss: 0.4797 - accuracy: 0.9008 - 4s/epoch - 17ms/step\n",
      "Epoch 112/200\n",
      "244/244 - 4s - loss: 0.4874 - accuracy: 0.9004 - 4s/epoch - 15ms/step\n",
      "Epoch 113/200\n",
      "244/244 - 4s - loss: 0.4632 - accuracy: 0.9030 - 4s/epoch - 16ms/step\n",
      "Epoch 114/200\n",
      "244/244 - 4s - loss: 0.4500 - accuracy: 0.9041 - 4s/epoch - 16ms/step\n",
      "Epoch 115/200\n",
      "244/244 - 4s - loss: 0.4414 - accuracy: 0.9063 - 4s/epoch - 16ms/step\n",
      "Epoch 116/200\n",
      "244/244 - 4s - loss: 0.4316 - accuracy: 0.9077 - 4s/epoch - 16ms/step\n",
      "Epoch 117/200\n",
      "244/244 - 4s - loss: 0.4257 - accuracy: 0.9085 - 4s/epoch - 15ms/step\n",
      "Epoch 118/200\n",
      "244/244 - 4s - loss: 0.4200 - accuracy: 0.9093 - 4s/epoch - 16ms/step\n",
      "Epoch 119/200\n",
      "244/244 - 4s - loss: 0.4136 - accuracy: 0.9105 - 4s/epoch - 15ms/step\n",
      "Epoch 120/200\n",
      "244/244 - 4s - loss: 0.4056 - accuracy: 0.9094 - 4s/epoch - 16ms/step\n",
      "Epoch 121/200\n",
      "244/244 - 4s - loss: 0.3995 - accuracy: 0.9112 - 4s/epoch - 16ms/step\n",
      "Epoch 122/200\n",
      "244/244 - 4s - loss: 0.3946 - accuracy: 0.9127 - 4s/epoch - 15ms/step\n",
      "Epoch 123/200\n",
      "244/244 - 4s - loss: 0.3897 - accuracy: 0.9121 - 4s/epoch - 16ms/step\n",
      "Epoch 124/200\n",
      "244/244 - 4s - loss: 0.3883 - accuracy: 0.9109 - 4s/epoch - 15ms/step\n",
      "Epoch 125/200\n",
      "244/244 - 4s - loss: 0.3790 - accuracy: 0.9141 - 4s/epoch - 16ms/step\n",
      "Epoch 126/200\n",
      "244/244 - 4s - loss: 0.3720 - accuracy: 0.9138 - 4s/epoch - 16ms/step\n",
      "Epoch 127/200\n",
      "244/244 - 4s - loss: 0.3653 - accuracy: 0.9153 - 4s/epoch - 16ms/step\n",
      "Epoch 128/200\n",
      "244/244 - 4s - loss: 0.3629 - accuracy: 0.9134 - 4s/epoch - 16ms/step\n",
      "Epoch 129/200\n",
      "244/244 - 4s - loss: 0.3552 - accuracy: 0.9146 - 4s/epoch - 16ms/step\n",
      "Epoch 130/200\n",
      "244/244 - 4s - loss: 0.3517 - accuracy: 0.9158 - 4s/epoch - 16ms/step\n",
      "Epoch 131/200\n",
      "244/244 - 4s - loss: 0.3516 - accuracy: 0.9153 - 4s/epoch - 16ms/step\n",
      "Epoch 132/200\n",
      "244/244 - 4s - loss: 0.3452 - accuracy: 0.9148 - 4s/epoch - 16ms/step\n",
      "Epoch 133/200\n",
      "244/244 - 4s - loss: 0.3390 - accuracy: 0.9175 - 4s/epoch - 17ms/step\n",
      "Epoch 134/200\n",
      "244/244 - 4s - loss: 0.3381 - accuracy: 0.9170 - 4s/epoch - 16ms/step\n",
      "Epoch 135/200\n",
      "244/244 - 4s - loss: 0.3358 - accuracy: 0.9153 - 4s/epoch - 16ms/step\n",
      "Epoch 136/200\n",
      "244/244 - 4s - loss: 0.3310 - accuracy: 0.9164 - 4s/epoch - 16ms/step\n",
      "Epoch 137/200\n",
      "244/244 - 4s - loss: 0.3289 - accuracy: 0.9162 - 4s/epoch - 16ms/step\n",
      "Epoch 138/200\n",
      "244/244 - 4s - loss: 0.3222 - accuracy: 0.9181 - 4s/epoch - 16ms/step\n",
      "Epoch 139/200\n",
      "244/244 - 4s - loss: 0.3211 - accuracy: 0.9163 - 4s/epoch - 16ms/step\n",
      "Epoch 140/200\n",
      "244/244 - 4s - loss: 0.3168 - accuracy: 0.9172 - 4s/epoch - 16ms/step\n",
      "Epoch 141/200\n",
      "244/244 - 4s - loss: 0.3139 - accuracy: 0.9163 - 4s/epoch - 16ms/step\n",
      "Epoch 142/200\n",
      "244/244 - 4s - loss: 0.3108 - accuracy: 0.9167 - 4s/epoch - 16ms/step\n",
      "Epoch 143/200\n",
      "244/244 - 4s - loss: 0.3086 - accuracy: 0.9172 - 4s/epoch - 16ms/step\n",
      "Epoch 144/200\n",
      "244/244 - 4s - loss: 0.3073 - accuracy: 0.9179 - 4s/epoch - 15ms/step\n",
      "Epoch 145/200\n",
      "244/244 - 4s - loss: 0.3059 - accuracy: 0.9170 - 4s/epoch - 15ms/step\n",
      "Epoch 146/200\n",
      "244/244 - 4s - loss: 0.3053 - accuracy: 0.9161 - 4s/epoch - 17ms/step\n",
      "Epoch 147/200\n",
      "244/244 - 5s - loss: 0.3068 - accuracy: 0.9153 - 5s/epoch - 20ms/step\n",
      "Epoch 148/200\n",
      "244/244 - 4s - loss: 0.2999 - accuracy: 0.9172 - 4s/epoch - 17ms/step\n",
      "Epoch 149/200\n",
      "244/244 - 4s - loss: 0.2994 - accuracy: 0.9166 - 4s/epoch - 15ms/step\n",
      "Epoch 150/200\n",
      "244/244 - 4s - loss: 0.2971 - accuracy: 0.9161 - 4s/epoch - 15ms/step\n",
      "Epoch 151/200\n",
      "244/244 - 4s - loss: 0.2940 - accuracy: 0.9167 - 4s/epoch - 16ms/step\n",
      "Epoch 152/200\n",
      "244/244 - 4s - loss: 0.2949 - accuracy: 0.9138 - 4s/epoch - 15ms/step\n",
      "Epoch 153/200\n",
      "244/244 - 4s - loss: 0.2904 - accuracy: 0.9154 - 4s/epoch - 15ms/step\n",
      "Epoch 154/200\n",
      "244/244 - 4s - loss: 0.2881 - accuracy: 0.9175 - 4s/epoch - 16ms/step\n",
      "Epoch 155/200\n",
      "244/244 - 4s - loss: 0.2865 - accuracy: 0.9158 - 4s/epoch - 15ms/step\n",
      "Epoch 156/200\n",
      "244/244 - 4s - loss: 0.2856 - accuracy: 0.9170 - 4s/epoch - 16ms/step\n",
      "Epoch 157/200\n",
      "244/244 - 4s - loss: 0.2849 - accuracy: 0.9164 - 4s/epoch - 16ms/step\n",
      "Epoch 158/200\n",
      "244/244 - 4s - loss: 0.2830 - accuracy: 0.9184 - 4s/epoch - 15ms/step\n",
      "Epoch 159/200\n",
      "244/244 - 4s - loss: 0.2839 - accuracy: 0.9173 - 4s/epoch - 16ms/step\n",
      "Epoch 160/200\n",
      "244/244 - 4s - loss: 0.2877 - accuracy: 0.9168 - 4s/epoch - 16ms/step\n",
      "Epoch 161/200\n",
      "244/244 - 4s - loss: 0.3083 - accuracy: 0.9108 - 4s/epoch - 17ms/step\n",
      "Epoch 162/200\n",
      "244/244 - 4s - loss: 0.3061 - accuracy: 0.9117 - 4s/epoch - 16ms/step\n",
      "Epoch 163/200\n",
      "244/244 - 4s - loss: 0.2864 - accuracy: 0.9163 - 4s/epoch - 15ms/step\n",
      "Epoch 164/200\n",
      "244/244 - 4s - loss: 0.2799 - accuracy: 0.9159 - 4s/epoch - 16ms/step\n",
      "Epoch 165/200\n",
      "244/244 - 4s - loss: 0.2763 - accuracy: 0.9168 - 4s/epoch - 16ms/step\n",
      "Epoch 166/200\n",
      "244/244 - 4s - loss: 0.2753 - accuracy: 0.9170 - 4s/epoch - 16ms/step\n",
      "Epoch 167/200\n",
      "244/244 - 4s - loss: 0.2744 - accuracy: 0.9184 - 4s/epoch - 15ms/step\n",
      "Epoch 168/200\n",
      "244/244 - 4s - loss: 0.2730 - accuracy: 0.9166 - 4s/epoch - 16ms/step\n",
      "Epoch 169/200\n",
      "244/244 - 4s - loss: 0.2728 - accuracy: 0.9168 - 4s/epoch - 16ms/step\n",
      "Epoch 170/200\n",
      "244/244 - 4s - loss: 0.2719 - accuracy: 0.9168 - 4s/epoch - 16ms/step\n",
      "Epoch 171/200\n",
      "244/244 - 4s - loss: 0.2722 - accuracy: 0.9162 - 4s/epoch - 16ms/step\n",
      "Epoch 172/200\n",
      "244/244 - 4s - loss: 0.2734 - accuracy: 0.9166 - 4s/epoch - 16ms/step\n",
      "Epoch 173/200\n",
      "244/244 - 4s - loss: 0.2728 - accuracy: 0.9162 - 4s/epoch - 16ms/step\n",
      "Epoch 174/200\n",
      "244/244 - 4s - loss: 0.2707 - accuracy: 0.9172 - 4s/epoch - 16ms/step\n",
      "Epoch 175/200\n",
      "244/244 - 4s - loss: 0.2727 - accuracy: 0.9161 - 4s/epoch - 16ms/step\n",
      "Epoch 176/200\n",
      "244/244 - 4s - loss: 0.2695 - accuracy: 0.9173 - 4s/epoch - 16ms/step\n",
      "Epoch 177/200\n",
      "244/244 - 4s - loss: 0.2698 - accuracy: 0.9166 - 4s/epoch - 16ms/step\n",
      "Epoch 178/200\n",
      "244/244 - 4s - loss: 0.2687 - accuracy: 0.9154 - 4s/epoch - 16ms/step\n",
      "Epoch 179/200\n",
      "244/244 - 4s - loss: 0.2684 - accuracy: 0.9157 - 4s/epoch - 16ms/step\n",
      "Epoch 180/200\n",
      "244/244 - 4s - loss: 0.2690 - accuracy: 0.9171 - 4s/epoch - 16ms/step\n",
      "Epoch 181/200\n",
      "244/244 - 7s - loss: 0.2678 - accuracy: 0.9175 - 7s/epoch - 30ms/step\n",
      "Epoch 182/200\n",
      "244/244 - 28s - loss: 0.2686 - accuracy: 0.9153 - 28s/epoch - 113ms/step\n",
      "Epoch 183/200\n",
      "244/244 - 4s - loss: 0.2700 - accuracy: 0.9179 - 4s/epoch - 18ms/step\n",
      "Epoch 184/200\n",
      "244/244 - 4s - loss: 0.2691 - accuracy: 0.9172 - 4s/epoch - 18ms/step\n",
      "Epoch 185/200\n",
      "244/244 - 4s - loss: 0.2653 - accuracy: 0.9172 - 4s/epoch - 18ms/step\n",
      "Epoch 186/200\n",
      "244/244 - 4s - loss: 0.2652 - accuracy: 0.9158 - 4s/epoch - 18ms/step\n",
      "Epoch 187/200\n",
      "244/244 - 4s - loss: 0.2650 - accuracy: 0.9161 - 4s/epoch - 18ms/step\n",
      "Epoch 188/200\n",
      "244/244 - 4s - loss: 0.2632 - accuracy: 0.9173 - 4s/epoch - 18ms/step\n",
      "Epoch 189/200\n",
      "244/244 - 4s - loss: 0.2646 - accuracy: 0.9173 - 4s/epoch - 18ms/step\n",
      "Epoch 190/200\n",
      "244/244 - 4s - loss: 0.2644 - accuracy: 0.9176 - 4s/epoch - 17ms/step\n",
      "Epoch 191/200\n",
      "244/244 - 4s - loss: 0.2633 - accuracy: 0.9163 - 4s/epoch - 15ms/step\n",
      "Epoch 192/200\n",
      "244/244 - 4s - loss: 0.2628 - accuracy: 0.9152 - 4s/epoch - 16ms/step\n",
      "Epoch 193/200\n",
      "244/244 - 4s - loss: 0.2633 - accuracy: 0.9167 - 4s/epoch - 17ms/step\n",
      "Epoch 194/200\n",
      "244/244 - 4s - loss: 0.2628 - accuracy: 0.9162 - 4s/epoch - 18ms/step\n",
      "Epoch 195/200\n",
      "244/244 - 4s - loss: 0.2629 - accuracy: 0.9180 - 4s/epoch - 18ms/step\n",
      "Epoch 196/200\n",
      "244/244 - 4s - loss: 0.2620 - accuracy: 0.9150 - 4s/epoch - 16ms/step\n",
      "Epoch 197/200\n",
      "244/244 - 4s - loss: 0.2611 - accuracy: 0.9177 - 4s/epoch - 16ms/step\n",
      "Epoch 198/200\n",
      "244/244 - 4s - loss: 0.2612 - accuracy: 0.9161 - 4s/epoch - 15ms/step\n",
      "Epoch 199/200\n",
      "244/244 - 4s - loss: 0.2610 - accuracy: 0.9168 - 4s/epoch - 17ms/step\n",
      "Epoch 200/200\n",
      "244/244 - 4s - loss: 0.2613 - accuracy: 0.9167 - 4s/epoch - 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de2743d120>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i care on gaza dignity are being now yet friends state\n",
      "how a lot for furor invitation missing national leaders to courtroom\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, 'i', 10))\n",
    "print(sentence_generation(model, tokenizer, 'how', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07-문자 단위 RNN(Char RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# 데 이 터 로 드\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\n",
    "\"11-0.txt\")\n",
    "f = open('11-0.txt', 'rb')\n",
    "sentences = []\n",
    "for sentence in f: # 데 이 터 로 부 터 한 줄 씩 읽 는 다.\n",
    "  sentence = sentence.strip() # strip()을 통 해 \\r, \\n을 제 거 한 다.\n",
    "  sentence = sentence.lower() # 소 문 자 화.\n",
    "  sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등 과 같 은 바 이 트\n",
    "  if len(sentence) > 0:\n",
    "    sentences.append(sentence)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159484"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = ' '.join(sentences)\n",
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 자 집 합 의 크 기 : 56\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(total_data)))\n",
    "vocab_size = len(char_vocab)\n",
    "print ('문 자 집 합 의 크 기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 자 집 합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n",
      "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', '%': 5, \"'\": 6, '(': 7, 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', '/': 13, '0': 14, '1': 15, 16: '2', 17: '3', 18: '4', 19: '5', '6': 20, '7': 21, '8': 22, '9': 23, 24: ':', 25: ';', 26: '?', '[': 27, ']': 28, 29: '_', 'a': 30, 'b': 31, 32: 'c', 33: 'd', 34: 'e', 'f': 35, 36: 'g', 'h': 37, 'i': 38, 'j': 39, 40: 'k', 41: 'l', 42: 'm', 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 48: 's', 49: 't', 50: 'u', 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
     ]
    }
   ],
   "source": [
    "# 문 자 에 고 유 한 정 수 부 여\n",
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "index_to_char = dict({v, k} for k, v in char_to_index.items())\n",
    "print('문 자 집 합 :',char_to_index)\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
